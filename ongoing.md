---
layout: page
title: Ongoing Projects
---

- [**Surviving academia**](https://research.tue.nl/en/publications/surviving-academia-studies-on-the-sustainability-of-science-and-a?_gl=1*euqtfz*_up*MQ..*_ga*ODE2NDM3MDMwLjE3Mzg5MzY3NjU.*_ga_JN37M497TT*MTczODkzNjc2NS4xLjAuMTczODkzNjc2NS4wLjAuMA..): <br>
  Andrea Kis's dissertation, Surviving Academia: Studies on the Sustainability of Science and Academic Careers, examines how systemic issues in academia - such as unreliable scientific outputs, flawed institutional structures, and researcher well-being - impact the sustainability of academic careers and science. Using mixed methods, she explores how poor research environments contribute to PhD attrition and systemic inefficiencies. The dissertation also develops and validates an Academic Research Values Scale to better understand researchers' motivations and how value alignment impacts career satisfaction and scientific integrity. By integrating sustainability concepts and policy recommendations, the work advocates for systemic reforms aimed at fostering a more supportive, ethical, and sustainable academic ecosystem.
<br>
<br>
- **Improving coordination in science**: <br>
  Coordination has been identified by many scholars as a key factor underlying challenges in science, including research waste, lack of cumulative progress, and neglect of critical field-specific challenges. In this PhD project, Sajedeh Rasti explores coordination through four distinct lenses: conceptual, motivational, implementational, and normative. It seeks to address questions such as: What are the dimensions of coordination? How can coordination be incentivized? How can scientists achieve consensus on prioritizing research topics? And, is coordination an epistemic responsibility?
<br>
<br>
- **Investigating the presence of factors that hinder the replicability and reproducibility of sports and exercise research**:<br>
  Two factors that hinder the replicability of studies are publication bias and low statistical power which can lead to inflated Type I error rates and overestimated effect sizes. In this PhD project, Cristian Mesquida attempts to estimate the average power of published studies and assess the presence of publication bias in the published literature. One way to improve replicability is to ensure studies are designed with high-power designs by conducting an a priori power analysis. Thus, a second goal is to assess the prevalence, computational reproducibility, and validity of a priori power analyses. Finally, although we set out to assess the overestimation of effect sizes in meta-analyses, poor reporting practices and low methodological quality of meta-analyses hindered our ability to reproduce and trust original results. Given these issues, the third goal is to assess the reporting practices and methodological quality of meta-analyses.
<br>
<br>
- **Neophilia—why our obsession with innovation leads to bad science**:<br>
  In this book (project in progress), Krist Vaesen argues that the many crises in science—the replication, methodology, generalizability, applicability and theory crises—are attributable to one primary factor: science’s obsession with novelty and innovation. He continues to show that, given this obsession, Open Science is unlikely effectively to resolve the crises. What is needed instead is an increase in scientific coordination—a science organized around concerted research programs rather than isolated studies. 
